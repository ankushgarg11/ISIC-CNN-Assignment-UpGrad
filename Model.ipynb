{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0b2e4db-391e-4fff-bae6-ac1f2036798c",
   "metadata": {},
   "source": [
    "**Table of Contents** <br>\n",
    "1. Load Images and Data Augmentation <br>\n",
    "2. Create Model <br>\n",
    "3. Train Model <br>\n",
    "4. Test Model <br>\n",
    "5. Submission <br>\n",
    "6. Conclussion <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d585c3d3-e80a-4bf1-94fd-5fb773fb8888",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17364\\3793969497.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m \u001b[1;31m# Plotting library\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__internal__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\__internal__\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\__internal__\\backend\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_initialize_variables\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minitialize_variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrack_variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\src\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \"\"\"\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\src\\models\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFunctional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\src\\engine\\functional.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # Plotting library\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "from keras.utils import np_utils\n",
    "from sklearn.datasets import load_files   \n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84507ee-f396-41b6-8260-745b1b04a297",
   "metadata": {},
   "source": [
    "## 1. Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "771b1605-b5d9-4115-9c9e-17b52f054e60",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (2235027896.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\ankush.garg.LOHIAGROUP.000\\AppData\\Local\\Temp\\ipykernel_12880\\2235027896.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    data_train_path = pd.read_csv(\"C:\\Users\\ankush.garg.LOHIAGROUP.000\\OneDrive - lohiagroup\\Documents\\Education\\EPGPML - C49\\4. ML-2\\CNN Assignment\\CNN_assignment\\Skin cancer ISIC The International Skin Imaging Collaboration\\Test\")\u001b[0m\n\u001b[1;37m                                                                                                                                                                                                                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "data_train_path = 'C:\\Users\\ankush.garg.LOHIAGROUP.000\\OneDrive - lohiagroup\\Documents\\Education\\EPGPML - C49\\4. ML-2\\CNN Assignment\\CNN_assignment\\Skin cancer ISIC The International Skin Imaging Collaboration\\Test'\n",
    "data_valid_path = 'C:\\Users\\ankush.garg.LOHIAGROUP.000\\OneDrive - lohiagroup\\Documents\\Education\\EPGPML - C49\\4. ML-2\\CNN Assignment\\CNN_assignment\\Skin cancer ISIC The International Skin Imaging Collaboration\\Train'\n",
    "data_test_path = 'C:\\Users\\ankush.garg.LOHIAGROUP.000\\OneDrive - lohiagroup\\Documents\\Education\\EPGPML - C49\\4. ML-2\\CNN Assignment\\CNN_assignment\\Skin cancer ISIC The International Skin Imaging Collaboration\\Train'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7add80eb-00f4-4968-94f4-5c8d9be8c8f2",
   "metadata": {},
   "source": [
    "**EDA** <br>\n",
    "\n",
    "Lets find out how many samples we have for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ad509a-bc3e-4065-bc4c-317022da02b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to load train, test, and validation datasets\n",
    "def load_data_raw (path):\n",
    "    data = load_files(path)\n",
    "    files = np.array(data['filenames'])\n",
    "    targets = np_utils.to_categorical(np.array(data['target']), 3)\n",
    "    \n",
    "    return files, targets\n",
    "\n",
    "train_filenames, train_targets = load_data_raw(data_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c69170-519f-418b-8daa-e2ebb4ac5f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_trimmed = [filename.split('/')[-2] for filename in train_filenames]\n",
    "classes_count = Counter(filenames_trimmed)\n",
    "\n",
    "# Plot the classes\n",
    "plt.bar(classes_count.keys(), classes_count.values(), color=['blue', 'orange', 'green'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651b73cd-661d-4073-8dbb-29d7e4bb0f94",
   "metadata": {},
   "source": [
    "Upsampling function for imbalanced data\n",
    "\n",
    "Using scikit learn's resample function I will create new samples of the under-represented data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f05468-e5af-41d0-88ff-4f5004e783ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_n_samples(filenames):\n",
    "    filenames_trimmed = [filename.split('/')[-2] for filename in filenames]\n",
    "    classes_count = Counter(filenames_trimmed)\n",
    "\n",
    "    # Plot the classes\n",
    "    plt.bar(classes_count.keys(), classes_count.values(), color=['blue', 'orange', 'green'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5536dc6-c181-4380-a6cf-81118336a4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample, shuffle\n",
    "\n",
    "# Choose one of the 3 for the feature_name\n",
    "feature_names = {0: 'melanoma', 1: 'nevus', 2: 'seborrheic_keratosis'}\n",
    "\n",
    "def upsample(filenames, targets, feature_name, n_samples = 1372):\n",
    "    upsample_idx = []\n",
    "    \n",
    "\n",
    "    # Find all the indices for nevus\n",
    "    for i, path in enumerate(filenames):\n",
    "        # If feature matches, save the index\n",
    "        if feature_name in path.split('/'):\n",
    "            upsample_idx.append(i)\n",
    "    \n",
    "    # Remove selected features from filenames to add the upsampled after\n",
    "    new_filenames = [filename for i, filename in enumerate(filenames) if i not in upsample_idx]\n",
    "    new_targets = [target for i, target in enumerate(targets) if i not in upsample_idx]\n",
    "\n",
    "    # Upsample\n",
    "    resampled_x, resampled_y = resample(filenames[upsample_idx], targets[upsample_idx], n_samples=n_samples, random_state=0)\n",
    "\n",
    "    # Add the upsampled features to new_filenames and new_targets\n",
    "    new_filenames += list(resampled_x)\n",
    "    new_targets += list(resampled_y) \n",
    "    \n",
    "    return np.array(new_filenames), np.array(new_targets)\n",
    "    \n",
    "# We upsample twice: once for each feature we want upsampled\n",
    "upsample_train_x, upsample_train_y = upsample(train_filenames, train_targets, feature_names[0])\n",
    "upsample_train_x, upsample_train_y = upsample(upsample_train_x, upsample_train_y, feature_names[2])\n",
    "\n",
    "plot_n_samples(upsample_train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93962cb-2d3b-4181-ae70-ca75e7e534a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image   \n",
    "\n",
    "# Convert the image paths to tensors Manually\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224,224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "\n",
    "train_filenames = paths_to_tensor(upsample_train_x)\n",
    "train_targets = upsample_train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce68e3b7-217c-4c00-ac85-2bf633218881",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=60\n",
    "\n",
    "# Transforms\n",
    "datagen_train = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally \n",
    "    height_shift_range=0.1,  # randomly shift images vertically\n",
    "    horizontal_flip=True)\n",
    "\n",
    "datagen_valid = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally\n",
    "    height_shift_range=0.1,  # randomly shift images vertically\n",
    "    horizontal_flip=True)\n",
    "\n",
    "datagen_test = ImageDataGenerator(\n",
    "    rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01834fe2-66ae-4d73-b811-9efe5510214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generators\n",
    "'''\n",
    "train_generator = datagen_train.flow_from_directory(\n",
    "        data_train_path,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "'''\n",
    "\n",
    "train_generator = datagen_train.flow(train_filenames, train_targets, batch_size=batch_size)\n",
    "\n",
    "valid_generator = datagen_valid.flow_from_directory(\n",
    "        data_valid_path,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "test_generator = datagen_test.flow_from_directory(\n",
    "        data_test_path,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=1,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0271e90a-6aab-4e42-ba0a-0ac475fd5b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = len(train_filenames)\n",
    "num_valid = len(valid_generator.filenames)\n",
    "num_test = len(test_generator.filenames)\n",
    "\n",
    "print(num_train, num_valid, num_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7921efe-ab4a-492f-bda6-7e056d7100e3",
   "metadata": {},
   "source": [
    "Get the class indices <br>\n",
    "\n",
    "To get the label we find the index of the 1 in the one hot encoded vector which should match the index in a dictionary. Eg: <br>\n",
    "\n",
    "- label = [1,0,0] ---> class_index = 0\n",
    "- label = [0,1,0] ---> class_index = 1\n",
    "- label = [0,0,1] ---> class_index = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80af0159-5cc0-4860-a586-41ad660b2502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class name to the index\n",
    "#class_2_indices = train_generator.class_indices\n",
    "class_2_indices = {'melanoma': 0, 'nevus': 1, 'seborrheic_keratoses': 2}\n",
    "print(\"Class to index:\", class_2_indices)\n",
    "\n",
    "# Reverse dict with the class index to the class name\n",
    "indices_2_class = {v: k for k, v in class_2_indices.items()}\n",
    "print(\"Index to class:\", indices_2_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ac433c-a075-4474-bcf0-f71b8a747b89",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Lets have a look at some of our images\n",
    "images, labels = train_generator.next()\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "fig.subplots_adjust(wspace=0.2, hspace=0.4)\n",
    "\n",
    "# Lets show the first 32 images of a batch\n",
    "for i, img in enumerate(images[:32]):\n",
    "    ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(img)\n",
    "    image_idx = np.argmax(labels[i])\n",
    "    ax.set(title=indices_2_class[image_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2252c7-9149-4035-b557-1eb67716cc51",
   "metadata": {},
   "source": [
    "## 2. Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565c28f3-bbe2-40e1-bfc7-326b19ca41c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.applications import ResNet50\n",
    "from keras.models import Model\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# x = MaxAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='elu')(x)\n",
    "x = Dropout(0.95)(x)\n",
    "# and a logistic layer\n",
    "predictions = Dense(3, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc063e71-0968-49b8-b5e5-b89d7442fa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e434e3-7f5f-4cf7-a067-4b3bace6ac78",
   "metadata": {},
   "source": [
    "## 3. Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a27ae8-23e5-4a1b-ac4e-bffc429d8988",
   "metadata": {},
   "source": [
    "Assign weights to imbalanced classes\n",
    "\n",
    "The dataset shows an imbalance. By assigning bigger weights to the misrepresented classes in the dataset we will help to correct this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402b390b-40da-4b57-aa9e-dd7220456484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Convert one hot encoded labels to ints\n",
    "train_targets_classes = [np.argmax(label) for label in train_targets]\n",
    "\n",
    "# Compute the weights\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                  np.unique(train_targets_classes),\n",
    "                                                  train_targets_classes)\n",
    "\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "print(class_weights_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd46353-7b8a-4bfb-89f5-b0f9aa5f1ccb",
   "metadata": {},
   "source": [
    "## 4. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7980e5a3-8832-47f0-89dc-598607895c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='aug_model.weights.best.hdf5', verbose=1, \n",
    "                               save_best_only=True)\n",
    "\n",
    "scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=5, min_lr=1e-8, verbose=1)\n",
    "\n",
    "early_stopper = EarlyStopping(monitor='val_loss', patience=10,\n",
    "                              verbose=0, restore_best_weights=True)\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                    class_weight= class_weights_dict,\n",
    "                    steps_per_epoch=num_train//batch_size,\n",
    "                    epochs=40,\n",
    "                    verbose=0,\n",
    "                    callbacks=[checkpointer, scheduler, TQDMNotebookCallback(), early_stopper],\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=num_valid//batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e06eedc-fdb0-48ef-801c-2f414ef499a0",
   "metadata": {},
   "source": [
    "## 5. Test model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e6fee6-3f8e-4523-aa70-5929b2476cc2",
   "metadata": {},
   "source": [
    "Load the model with the best Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49053f5-ee47-40af-80a2-5fbbae9da16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weights that yielded the best validation accuracy\n",
    "model.load_weights('aug_model.weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9f5b13-d93e-4196-a39a-12f209a676cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate_generator(test_generator, steps=num_test//1, verbose=1)\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95dd6d2-4b2a-46c1-968d-d0806e0f705d",
   "metadata": {},
   "source": [
    "Predictions for the test data\n",
    "\n",
    "- task_1: the model's predicted probability that the image depicts melanoma\n",
    "- task_2: the model's predicted probability that the image depicts seborrheic keratosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b291603f-bace-46bb-be10-42e0e84ce8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(test_generator, steps=num_test)\n",
    "\n",
    "task_1 = pd.DataFrame(data=[desease[0] for desease in predictions])\n",
    "task_2 = pd.DataFrame(data=[desease[2] for desease in predictions])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28958fad-d738-45fa-8237-c7371e40d6d4",
   "metadata": {},
   "source": [
    "RocAuc Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796432a7-3e98-4ec0-9ea9-5bb75d4df6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "ground_truth = pd.read_csv(\"../input/udacitydermatologistai/repository/udacity-dermatologist-ai-2ec0ca9/ground_truth.csv\")\n",
    "labels = np_utils.to_categorical(np.array(test_generator.classes), 3)\n",
    "\n",
    "roc_auc_all = roc_auc_score(labels, predictions)\n",
    "roc_auc_task_1 = roc_auc_score(ground_truth['task_1'], task_1)\n",
    "roc_auc_task_2 = roc_auc_score(ground_truth['task_2'], task_2)\n",
    "\n",
    "print('Roc auc score for all data is: {}'.format(roc_auc_all))\n",
    "print('Roc auc score for task 1 is: {}'.format(roc_auc_task_1))\n",
    "print('Roc auc score for task 2 is: {}'.format(roc_auc_task_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0834b968-8a56-4b9d-b3d8-f04ee0faf32f",
   "metadata": {},
   "source": [
    "Lets visualize some of our predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caf9daf6-e3e0-4d03-94eb-8cb49f2609b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_data_raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12880\\1920613789.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_filenames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_test_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'load_data_raw' is not defined"
     ]
    }
   ],
   "source": [
    "test_filenames, test_targets = load_data_raw(data_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc84961b-895d-44ea-bf4a-73aa3ecda556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(img_file, img_target):\n",
    "\n",
    "    img = image.load_img(img_file, target_size=(224,224))\n",
    "    img = image.img_to_array(img)/255\n",
    "    img_expand = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    # Make a prediction\n",
    "    prediction = model.predict(img_expand, steps=1)\n",
    "    image_idx = np.argmax(prediction[0])\n",
    "    prediction_string = indices_2_class[image_idx]\n",
    "    \n",
    "    # Get the real label's name\n",
    "    label_idx = np.argmax(img_target)\n",
    "    real_label = indices_2_class[label_idx]\n",
    "    \n",
    "    # Plot predictions\n",
    "    title = \"Prediction: {}\\nReal: {}\".format(prediction_string, real_label)\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    plt.title(title)\n",
    "    \n",
    "    pred_df = pd.DataFrame({'Cancer type':['melanoma', 'nevus', 'seborrheic keratosis'], 'val':prediction[0]})\n",
    "    ax = pred_df.plot.barh(x='Cancer type', y='val', title=\"Predictions\", grid=True)\n",
    "    \n",
    "random_index = np.random.randint(0, len(test_generator.filenames))\n",
    "plot_prediction(test_filenames[random_index], test_targets[random_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57a90b1-dade-44f4-9229-d7f69bb70056",
   "metadata": {},
   "source": [
    "Performance curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a4429a-f813-49cd-90e2-25fd06a19d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plts, (ax1, ax2) = plt.subplots(1,2, figsize=(20,5))\n",
    "\n",
    "# summarize history for accuracy\n",
    "ax1.plot(history.history['acc'])\n",
    "ax1.plot(history.history['val_acc'])\n",
    "ax1.set_title('model accuracy')\n",
    "ax1.set(xlabel='epoch', ylabel='accuracy')\n",
    "ax1.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "ax2.plot(history.history['loss'])\n",
    "ax2.plot(history.history['val_loss'])\n",
    "ax2.set_title('model loss')\n",
    "ax2.set(xlabel='epoch', ylabel='loss')\n",
    "ax2.legend(['train', 'val'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9852c54-f9ff-4e4f-8386-f9d913bb9678",
   "metadata": {},
   "source": [
    "## 5. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404b3198-a0d0-4019-85e1-8b436ad65061",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"../input/udacitydermatologistai/repository/udacity-dermatologist-ai-2ec0ca9/sample_predictions.csv\")\n",
    "submission['task_1'] = task_1\n",
    "submission['task_2'] = task_2\n",
    "submission.to_csv(\"submission_dermatologist.csv\", index=False)\n",
    "display(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909f0b13-9dc6-4467-8859-d3f30ae004cf",
   "metadata": {},
   "source": [
    "## 6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6cb084-1196-4f6f-819a-45cee4e67f9a",
   "metadata": {},
   "source": [
    "Due to the nature of the problem, it is very important that we make no mistake when identifying a patient as not sick. We prefer to send someone who is not sick for more tests, rather than someone who is sick home. This is what we know as recall, and we want a value for recall as close to 1 as possible. To improve recall what we can do is set a lower threshold to idenfify someone as sick or not sick, therefore only the pateients with a really low probability of melanoma will be let go, any others with a higher predicted chance will be held for more tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed69db40-8adf-4d1f-aa96-2aa655e0daf5",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d422db-7697-4e8f-ae69-6b0fad4b8541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Confusion matrix for all classes\n",
    "y_true = test_generator.classes\n",
    "y_pred = [np.argmax(x) for x in predictions]\n",
    "\n",
    "labels = [\"melanoma\", \"nevus\", \"keratoses\"]\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] # Normalize confusion matrix\n",
    "ax = sns.heatmap(cm, annot=True)\n",
    "ax.xaxis.set_ticklabels(labels)\n",
    "ax.yaxis.set_ticklabels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba2e497-8865-4a31-b82e-9aceec513733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(pred_target_y, filenames):\n",
    "    melanoma_idx = []\n",
    "      \n",
    "    # Find all the indices for nevus\n",
    "    for i, path in enumerate(filenames):\n",
    "        # If feature matches, save the index\n",
    "        if 'melanoma' in path.split('/'):\n",
    "            melanoma_idx.append(i)\n",
    "            \n",
    "    bening_preds = [pred for i, pred in enumerate(pred_target_y) if i not in melanoma_idx]\n",
    "    malignant_preds = [pred for i, pred in enumerate(pred_target_y) if i in melanoma_idx]\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1,figsize=(15,6))\n",
    "    \n",
    "    ax.set_title('Malignant vs. Bening')\n",
    "    sns.distplot(bening_preds, hist=True, kde=True, label=\"Benign\", bins=35)\n",
    "    sns.distplot(malignant_preds, hist=True, kde=True, label=\"Malignant\", bins=35, axlabel=\"Probability Malignant\")\n",
    "    ax.legend()\n",
    "    ax.xaxis.set_ticks(np.arange(0, 1.1, 0.1))\n",
    "\n",
    "plot_distribution(task_1.values, test_generator.filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a01330-4b65-4d5d-9869-2624f1cda90a",
   "metadata": {},
   "source": [
    "__Insights__\n",
    "\n",
    "We can see the a little the separation between malignant and bening lesions. This plot could be used to find the best threshold that maximizes the amount of people that have malignant lesions.\n",
    "\n",
    "- The model predicts that about 50% of the malignant lesions are bening (Really close to 0%)\n",
    "- The model predicts correctly 50% of the malignant lesions as malignant (as we can see in the confusion matrix)\n",
    "- In the event that we had to choose a threshold (this is dangerous because a lot of our malignant lesions are very near the 0), we could say that a \"good\" threshold is around 0.05, where it identifies a lot of malignant lesions (more than 50% at least) and leaves back most benign lesions (more than 90%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c942598-1346-47f0-8593-13030dac9d43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
